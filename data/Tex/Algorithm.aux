\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Deep Q Networkの擬似コード}{1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Deep Q-learning with experience replay}}{1}}
\newlabel{alg:dqn}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Atari Gamesの環境のラップ処理}{1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces $reset_{\mathrm  {noop}}()$}}{2}}
\newlabel{alg:noop_reset}{{2}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces $step_{\mathrm  {repeat}}(a_t)$}}{2}}
\newlabel{alg:max_and_skip}{{3}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces $observe_{\mathrm  {gray84}}()$}}{2}}
\newlabel{alg:process_frame84}{{4}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces $step_{\mathrm  {stack}}(a_t)$}}{2}}
\newlabel{alg:frame_stack}{{5}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces $reward_{\mathrm  {clip}}()$}}{3}}
\newlabel{alg:clipped_reward_wrapper}{{6}{3}}
